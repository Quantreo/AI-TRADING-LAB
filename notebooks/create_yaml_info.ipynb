{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# How Quantreo Generates “Features Info” YAML Files\n",
    "\n",
    "This notebook illustrates the philosophy behind **Quantreo’s Feature Information pipeline** how raw market data is transformed into structured YAML summaries before being interpreted by the **DSR agent** (Definition–Stability–Robustness).\n",
    "\n",
    "⚠️ **Educational version only.**\n",
    "This notebook is designed to explain *the logic* behind the process, without revealing the proprietary code or optimizations used in production.\n",
    "\n",
    "---\n",
    "\n",
    "### What the real Quantreo pipeline includes\n",
    "\n",
    "- Multi-asset and multi-timeframe universes\n",
    "- Stationarity and redundancy checks (VIF, MI filtering)\n",
    "- Rolling and cross-asset robustness validation\n",
    "- Parallelized computations optimized with Numba\n",
    "\n",
    "---\n",
    "\n",
    "This simplified version focuses on clarity, helping you understand how Quantreo structures empirical relations between features and redictive targets before DSR analysis.\n"
   ],
   "id": "d3457b9cc1fd3393"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:55:14.352877Z",
     "start_time": "2025-11-19T13:55:14.330182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================\n",
    "# 1. Imports\n",
    "# ==============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "np.random.seed(42)"
   ],
   "id": "4f97df0a8b66c818",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:55:14.493246Z",
     "start_time": "2025-11-19T13:55:14.431521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================\n",
    "# 2. Simulate basic market data\n",
    "# ==============================================================\n",
    "prices = np.cumprod(1 + np.random.normal(0, 0.001, 2000))\n",
    "df = pd.DataFrame({\"close\": prices})\n",
    "df[\"open\"] = df[\"close\"].shift(1)\n",
    "df[\"high\"] = df[[\"open\", \"close\"]].max(axis=1) * (1 + np.random.rand(len(df)) * 0.002)\n",
    "df[\"low\"] = df[[\"open\", \"close\"]].min(axis=1) * (1 - np.random.rand(len(df)) * 0.002)\n",
    "df.dropna(inplace=True)"
   ],
   "id": "dc060a7dc1ee42b2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-19T13:57:36.145944Z",
     "start_time": "2025-11-19T13:57:05.995009Z"
    }
   },
   "source": [
    "# ==============================================================\n",
    "# 3. Generate Quantreo-style features\n",
    "# ==============================================================\n",
    "\n",
    "\"\"\"\n",
    "Quantreo groups its feature functions into logical categories:\n",
    "- fe.volatility.*        → volatility estimators\n",
    "- fe.trend.*             → slope and persistence measures\n",
    "- fe.math.*              → statistical & distribution metrics\n",
    "- fe.candle.*            → candle-based structural ratios\n",
    "- fe.transformation.*    → smoothing, normalization, etc.\n",
    "\n",
    "Below is a simplified example using Quantreo’s feature engineering tools\n",
    "to create a few core variables used later in the Features Info pipeline.\n",
    "\"\"\"\n",
    "\n",
    "import quantreo.features_engineering as fe\n",
    "\n",
    "# --- 3.1 Base transformations ---\n",
    "df[\"close_smoothed\"] = fe.transformation.mma(df=df, col=\"close\", window_size=3)\n",
    "df[\"returns_10\"] = df[\"close\"].pct_change(10)\n",
    "df[\"abs_returns_10\"] = np.abs(df[\"returns_10\"])\n",
    "\n",
    "# --- 3.2 Volatility & Trend ---\n",
    "df[\"rs_vol_60\"] = fe.volatility.rogers_satchell_volatility(\n",
    "    df=df, high_col=\"high\", low_col=\"low\", open_col=\"open\", close_col=\"close\", window_size=60\n",
    ")\n",
    "df[\"rs_vol_120\"] = fe.volatility.rogers_satchell_volatility(\n",
    "    df=df, high_col=\"high\", low_col=\"low\", open_col=\"open\", close_col=\"close\", window_size=120\n",
    ")\n",
    "\n",
    "df[\"linear_slope_60\"] = fe.trend.linear_slope(df=df, col=\"close\", window_size=60)\n",
    "df[\"linear_slope_120\"] = fe.trend.linear_slope(df=df, col=\"close\", window_size=120)\n",
    "\n",
    "# --- 3.3 Statistical Shape & Tail Behavior ---\n",
    "df[\"tail_returns_100\"] = fe.math.tail_index(df=df, col=\"abs_returns_10\", window_size=100, k_ratio=0.10)\n",
    "df[\"tail_vol_100\"] = fe.math.tail_index(df=df, col=\"rs_vol_60\", window_size=100, k_ratio=0.10)\n",
    "df[\"hurst_100\"] = fe.math.hurst(df=df, col=\"close_smoothed\", window_size=100)\n",
    "\n",
    "df[\"skew_100\"] = fe.math.skewness(df=df, col=\"returns_10\", window_size=100)\n",
    "df[\"bimodality_coef_200\"] = fe.math.bimodality_coefficient(df=df, col=\"returns_10\", window_size=200)\n",
    "\n",
    "# --- 3.4 Candle Structure ---\n",
    "df[\"price_dist_0_25_100\"] = fe.candle.price_distribution(\n",
    "    df=df, col=\"close\", window_size=100, start_percentage=0.0, end_percentage=0.25\n",
    ")\n",
    "df[\"price_dist_75_100_100\"] = fe.candle.price_distribution(\n",
    "    df=df, col=\"close\", window_size=100, start_percentage=0.75, end_percentage=1.00\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:57:36.158170Z",
     "start_time": "2025-11-19T13:57:36.155951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================\n",
    "# 4. Create a target variable\n",
    "# ==============================================================\n",
    "df[\"future_rs_vol_60\"] = df[\"rs_vol_60\"].shift(-60)"
   ],
   "id": "5a55a7314e1c23e0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:57:36.169164Z",
     "start_time": "2025-11-19T13:57:36.165660Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "da570f3aa96112c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['close', 'open', 'high', 'low', 'close_smoothed', 'returns_10',\n",
       "       'abs_returns_10', 'rs_vol_60', 'rs_vol_120', 'linear_slope_60',\n",
       "       'linear_slope_120', 'tail_returns_100', 'tail_vol_100', 'hurst_100',\n",
       "       'skew_100', 'bimodality_coef_200', 'price_dist_0_25_100',\n",
       "       'price_dist_75_100_100', 'future_rs_vol_60'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:57:36.193425Z",
     "start_time": "2025-11-19T13:57:36.180881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 5. Compute simplified relations (correlation + MI proxy)\n",
    "# ==============================================================\n",
    "def compute_relations(x: pd.Series, y: pd.Series) -> dict:\n",
    "    \"\"\"Compute basic correlation and covariance-based MI proxy.\"\"\"\n",
    "    x, y = x.dropna(), y.dropna()\n",
    "    if len(x) != len(y):\n",
    "        min_len = min(len(x), len(y))\n",
    "        x, y = x.iloc[-min_len:], y.iloc[-min_len:]\n",
    "\n",
    "    corr = x.corr(y)\n",
    "    cov = np.cov(x, y)[0, 1]\n",
    "    mi = cov / np.sqrt(x.var() * y.var()) if x.var() > 0 and y.var() > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"correlation\": round(float(corr), 3) if pd.notnull(corr) else None,\n",
    "        \"mutual_info\": round(float(mi), 3) if pd.notnull(mi) else None,\n",
    "    }\n",
    "\n",
    "# Select features to analyze\n",
    "feature_cols = [\n",
    "    'returns_10',\n",
    "       'abs_returns_10', 'rs_vol_60', 'rs_vol_120', 'linear_slope_60',\n",
    "       'linear_slope_120', 'tail_returns_100', 'tail_vol_100', 'hurst_100',\n",
    "       'skew_100', 'bimodality_coef_200', 'price_dist_0_25_100',\n",
    "       'price_dist_75_100_100', 'future_rs_vol_60'\n",
    "]\n",
    "\n",
    "relations = {col: compute_relations(df[col], df[\"future_rs_vol_60\"]) for col in feature_cols}"
   ],
   "id": "56d30c1bd8f22708",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:58:53.628687Z",
     "start_time": "2025-11-19T13:58:53.621079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================\n",
    "# 6. Build YAML dictionary\n",
    "# ==============================================================\n",
    "yaml_dict = {\n",
    "    \"target\": \"future_rs_vol_60\",\n",
    "    \"relations\": relations,\n",
    "    \"meta\": {\n",
    "        \"comment\": (\n",
    "            \"Demonstration of how Quantreo structures empirical relations \"\n",
    "            \"between features and predictive targets before interpretation by the DSR agent.\"\n",
    "        ),\n",
    "        \"generated_with\": \"Quantreo educational pipeline (simplified demo)\",\n",
    "        \"note\": (\n",
    "            \"The real implementation includes rolling robustness tests, \"\n",
    "            \"cross-asset validation, and automatic feature ranking.\"\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "# ==============================================================\n",
    "# 7. Save example YAML file\n",
    "# ==============================================================\n",
    "output_path = \"results/rs_vol.yaml\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    yaml.dump(yaml_dict, f, sort_keys=False)\n",
    "\n",
    "print(f\"✅ YAML file successfully saved to: {output_path}\\n\")\n",
    "print(yaml.dump(yaml_dict, sort_keys=False))"
   ],
   "id": "e2f41602c3cd8a55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ YAML file successfully saved to: results/rs_vol.yaml\n",
      "\n",
      "target: future_rs_vol_60\n",
      "relations:\n",
      "  returns_10:\n",
      "    correlation: 0.119\n",
      "    mutual_info: -0.072\n",
      "  abs_returns_10:\n",
      "    correlation: -0.022\n",
      "    mutual_info: 0.115\n",
      "  rs_vol_60:\n",
      "    correlation: -0.307\n",
      "    mutual_info: 1.0\n",
      "  rs_vol_120:\n",
      "    correlation: -0.388\n",
      "    mutual_info: 0.601\n",
      "  linear_slope_60:\n",
      "    correlation: 0.212\n",
      "    mutual_info: 0.056\n",
      "  linear_slope_120:\n",
      "    correlation: 0.08\n",
      "    mutual_info: 0.254\n",
      "  tail_returns_100:\n",
      "    correlation: 0.149\n",
      "    mutual_info: -0.184\n",
      "  tail_vol_100:\n",
      "    correlation: -0.236\n",
      "    mutual_info: -0.225\n",
      "  hurst_100:\n",
      "    correlation: 0.065\n",
      "    mutual_info: -0.01\n",
      "  skew_100:\n",
      "    correlation: -0.213\n",
      "    mutual_info: 0.223\n",
      "  bimodality_coef_200:\n",
      "    correlation: 0.036\n",
      "    mutual_info: 0.019\n",
      "  price_dist_0_25_100:\n",
      "    correlation: 0.112\n",
      "    mutual_info: -0.201\n",
      "  price_dist_75_100_100:\n",
      "    correlation: -0.047\n",
      "    mutual_info: 0.055\n",
      "  future_rs_vol_60:\n",
      "    correlation: 1.0\n",
      "    mutual_info: 1.0\n",
      "meta:\n",
      "  comment: Demonstration of how Quantreo structures empirical relations between features\n",
      "    and predictive targets before interpretation by the DSR agent.\n",
      "  generated_with: Quantreo educational pipeline (simplified demo)\n",
      "  note: The real implementation includes rolling robustness tests, cross-asset validation,\n",
      "    and automatic feature ranking.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "950e454c72db5ab4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
